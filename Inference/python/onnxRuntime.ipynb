{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, './../../Research')\n",
    "\n",
    "import onnxruntime\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from time import time\n",
    "\n",
    "from utils import get_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    \"\"\"Tensor to numpy array\"\"\"\n",
    "    \n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model path and holdout images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX model\n",
    "model_path = './../../Models/fashionNet.onnx'\n",
    "classes = get_classes()\n",
    "\n",
    "# Folder of images\n",
    "holdout_folder = \"./../data/fashionmnist/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNXruntime engine\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_per_image = []\n",
    "time_start = time()\n",
    "\n",
    "# Inferencing Images one by one\n",
    "for images in tqdm(os.listdir(holdout_folder)):\n",
    "    if not images.endswith('.pgm'):\n",
    "        continue\n",
    "    time_img_st = time()\n",
    "    img_name = os.path.join(holdout_folder, images)\n",
    "    img_label = classes[int(os.path.basename(img_name).split('_')[0])]\n",
    "\n",
    "    img_PIL = Image.open(img_name)\n",
    "    img = transforms.ToTensor()(img_PIL)\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    # compute ONNX Runtime output prediction\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img)}\n",
    "    ort_outs = torch.tensor(ort_session.run(None, ort_inputs), dtype=torch.float32)\n",
    "    \n",
    "    ort_outs_tensor = ort_outs[0].squeeze(0)\n",
    "\n",
    "    preds = torch.argmax(ort_outs_tensor, dim=0)\n",
    "    pred_label = classes[preds]\n",
    "    \n",
    "    total_predictions += 1\n",
    "    if pred_label == img_label:\n",
    "        correct_predictions += 1\n",
    "    time_img_en = time()\n",
    "    time_per_image.append(time_img_en - time_img_st)\n",
    "time_end = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy         = \", correct_predictions*100/total_predictions)\n",
    "print(\"Total time (sec) = \", time_end - time_start)\n",
    "print(\"Latency          = \", np.mean(time_per_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats from my Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionNet\n",
    "\n",
    "# Accuracy         =  92.33844103930713\n",
    "# Total time (sec) =  4.945388555526733\n",
    "# Latency          =  0.001576131856258832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torNet\n",
    "\n",
    "# Accuracy         =  91.87208527648235\n",
    "# Total time (sec) =  29.028265476226807\n",
    "# Latency          =  0.009158259149712774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientNet\n",
    "\n",
    "# Accuracy         =  89.44037308461026\n",
    "# Total time (sec) =  48.72265887260437\n",
    "# Latency          =  0.01540562941343446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torNet\n",
    "\n",
    "# Percentage Accuracy = 91.8721\n",
    "# Total time taken   = 48.842\n",
    "# Latency            = 0.0162661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionCNN\n",
    "\n",
    "# Percentage Accuracy = 92.3384\n",
    "# Total time taken   = 2.8788\n",
    "# Latency            = 0.000956716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient Net\n",
    "\n",
    "#  Unable to run due to the following error\n",
    "'''\n",
    "terminate called after throwing an instance of 'std::out_of_range'\n",
    "  what():  Attribute not found: pads\n",
    "Aborted (core dumped)\n",
    "root@0c209c19480f:/data/Inference/bin# clear\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
