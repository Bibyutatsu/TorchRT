{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Will use pytorcone_channelightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from networks import torNet, FashionCNN, efficientNet\n",
    "from utils import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    \"\"\"Function for converting image to plt subplot\n",
    "    \n",
    "    Args:\n",
    "        img: The image to plot\n",
    "        one_channel: Optional, Bool for one channel input image\n",
    "    \"\"\"\n",
    "    \n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    \"\"\"Pytorch Lightning Module for defining and training the model\n",
    "    \n",
    "    This is a Pytorch Lightning clas which helps us to rewrite the pytorch code without the boilerplate \n",
    "    codes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, val_image_count=6):\n",
    "        \"\"\"Init the model\n",
    "        \n",
    "        Args:\n",
    "            model: Model to train\n",
    "            val_image_count: No of images to log during validation\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.val_image_count = val_image_count\n",
    "        \n",
    "        # Saving the best model\n",
    "        self.lowest_val_acc = 0\n",
    "        self.best_epoch = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward method for the net\n",
    "        Args:\n",
    "            x: Any tensor to input in the model\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step\n",
    "        \n",
    "        Args:\n",
    "            batch: Batches of input data from train_dataloader\n",
    "            batch_idx: Index of the Batch or the step count\n",
    "        \n",
    "        Returns:\n",
    "            A dict containing loss and logs for tensorboard\n",
    "        \"\"\"\n",
    "        \n",
    "        x, y = batch\n",
    "        yt = self(x)\n",
    "        loss = F.cross_entropy(yt, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Validation step\n",
    "        \n",
    "        Args:\n",
    "            batch: Batches of input data from val_dataloader\n",
    "            batch_idx: Index of the Batch or the step count\n",
    "        \n",
    "        Returns:\n",
    "            A dict containing validation loss and validation accuracy\n",
    "        \"\"\"\n",
    "        \n",
    "        x, y = batch\n",
    "\n",
    "        yt = self(x)\n",
    "        loss = F.cross_entropy(yt, y)\n",
    "        \n",
    "        preds = torch.argmax(yt, dim=1)\n",
    "        val_acc = torch.sum(y == preds).item() / (len(y) * 1.0)\n",
    "#         self.logger.experiment.add_graph(self.model, x)\n",
    "        if batch_idx == 0:\n",
    "            probs = [F.softmax(el, dim=0)[i].item() for i, el in zip(preds[:self.val_image_count], \n",
    "                                                                     yt[:self.val_image_count])]\n",
    "            self.logger.experiment.add_figure('predictions vs. actuals',\n",
    "                                              self.plot_classes_preds(preds[:self.val_image_count], \n",
    "                                                                      probs, x[:self.val_image_count], \n",
    "                                                                      y[:self.val_image_count]),\n",
    "                                              global_step=self.current_epoch)\n",
    "        \n",
    "        output = {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': torch.tensor(val_acc),\n",
    "        }\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"After all the Validation steps are completed\n",
    "        \n",
    "        Args:\n",
    "            outputs: All the outputs of validation steps\n",
    "        Returns:\n",
    "            results: A dict containing progress bar update and tensorboard logs\n",
    "        \"\"\"\n",
    "        \n",
    "        val_acc_mean = 0\n",
    "        for output in outputs:\n",
    "            val_acc_mean += output['val_acc']\n",
    "\n",
    "        val_acc_mean /= len(outputs)\n",
    "        tqdm_dict = {'val_acc': val_acc_mean.item()}\n",
    "        \n",
    "        # Saving_best_epoch\n",
    "        if val_acc_mean.item() > self.lowest_val_acc:\n",
    "            self.lowest_val_acc = val_acc_mean.item()\n",
    "            self.best_epoch = self.current_epoch\n",
    "            torch.save(self.model.state_dict(), './../Models/best_model.pth')\n",
    "\n",
    "        results = {\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': {'val_acc': val_acc_mean, 'epoch': self.current_epoch, 'best_epoch': self.best_epoch}\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def plot_classes_preds(self, preds, probs, images, labels):\n",
    "        \"\"\"Plot the images in a matplotlib figure\n",
    "        \n",
    "        Args:\n",
    "            preds: Predicted label ids of images\n",
    "            probs: Prediction probabilities of the class\n",
    "            images: Images to be plotted\n",
    "            labels: Labels corresponding to preds\n",
    "        \n",
    "        Returns:\n",
    "            fig: The matplotlip figure containing subplots of image and labels\n",
    "        \"\"\"\n",
    "        \n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        for idx in range(images.shape[0]):\n",
    "            ax = fig.add_subplot(1, images.shape[0], idx+1, xticks=[], yticks=[])\n",
    "            matplotlib_imshow(images[idx], one_channel=True)\n",
    "            ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "                self.classes[preds[idx]],\n",
    "                probs[idx] * 100.0,\n",
    "                self.classes[labels[idx]]),\n",
    "                        color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "        return fig\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configuring the optimizers to use for training\"\"\"\n",
    "        \n",
    "        # return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return torch.optim.RMSprop(self.parameters(), lr=0.0001, weight_decay=1e-6)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Dataloader for training\"\"\"\n",
    "        \n",
    "        train = get_data(train=True)\n",
    "        loader = DataLoader(train, batch_size=32, num_workers=4, shuffle=True, pin_memory=True)\n",
    "        return loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Dataloader for validation\"\"\"\n",
    "        \n",
    "        val = get_data()\n",
    "        self.classes = val.classes\n",
    "        loader = DataLoader(val, batch_size=32, num_workers=4, shuffle=False, pin_memory=True)\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to train\n",
    "model = Net(efficientNet())\n",
    "\n",
    "# Checkpoint incase there is an interruption\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(os.getcwd(), './lightning_logs/checkpoints'),\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    prefix=''\n",
    ")\n",
    "\n",
    "# Trainer to train the model on all GPUs for 20 epochs\n",
    "trainer = Trainer(max_epochs=20, gpus=-1, checkpoint_callback=checkpoint_callback)#, resume_from_checkpoint='./lightning_logs/Checkpoints_efficientNet/_ckpt_epoch_19.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)   # Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
